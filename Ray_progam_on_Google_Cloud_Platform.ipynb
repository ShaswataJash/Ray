{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ray_progam_on_Google_Cloud_Platform.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOQvuVPFSokNhIm4a+3+kCf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShaswataJash/Ray/blob/master/Ray_progam_on_Google_Cloud_Platform.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPwmlnDBW9Kv",
        "colab_type": "text"
      },
      "source": [
        "**INTRODUCTION: The notebook demonstrates how to create ray-cluster (https://docs.ray.io/en/latest/installation.html) on Google Cloud Platform (GCP) and then run a ray-program remotely on it from google-colab notebook.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_6yMZpERnaK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!whoami\n",
        "!python -V"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ricEd2ooWfZ3",
        "colab_type": "text"
      },
      "source": [
        "**Install ray library - current notebook is tested against 0.8.6 version of ray**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fu3x5TY_bDs6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install ray==0.8.6"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWE2zI_cK0qC",
        "colab_type": "text"
      },
      "source": [
        "**Run following cell only during development in local node. If you run following cell, it will create a local ray-cluster with single node. The single node acts as head-node of the cluster. Develop your ray-program using this local cluster. Once you have successfully developed the ray-program, then save that ray-program as python (.py) file which can be later submitted to a remote ray-cluster running in Google Cloud Platform (GCP) compute cluster.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQpKfN3KkrGe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ray stop\n",
        "!rm -Rf /tmp/ray\n",
        "!ray start --head --port=6379 --object-manager-port=8076 --include-webui=True --webui-host=0.0.0.0 &"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vc0Zl0B6MVyR",
        "colab_type": "text"
      },
      "source": [
        "**Create the following directory in local node which will be used to write final output from ray-program. When you are developing the ray-program locally, write the output to this directory present in local node. We will be mapping the same directoy path even in remote ray-cluster so that there is no need to change the ray-program whether it is running locally or remotely.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8VNaCfPJ6rE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir /tmp/ray_local_directory_mount"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqJmM-8nM8gB",
        "colab_type": "text"
      },
      "source": [
        "**Note the %%writefile magic code of jupyter notebook used in the following cell. When you are developing the ray-program locally comment out %%writefile as** \n",
        "\n",
        "`#%%writefile ray_test.py`\n",
        "\n",
        "**Once the ray-program is developed successfully in local node, write the content of the following cell as python(.py) file which can be now submitted to remote ray cluster.**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6Jqj3aSk1x9",
        "colab_type": "code",
        "cellView": "code",
        "colab": {}
      },
      "source": [
        "#test program taken from https://towardsdatascience.com/how-to-scale-python-on-every-major-cloud-provider-5e5df3e88274\n",
        "\n",
        "%%writefile ray_test.py\n",
        "\n",
        "from collections import Counter\n",
        "import socket\n",
        "import time\n",
        "import ray\n",
        "\n",
        "ray.shutdown()\n",
        "ray.init(address='auto', ignore_reinit_error=True)\n",
        "\n",
        "print('''This cluster consists of {} nodes in total {} CPU resources in total '''.format(len(ray.nodes()), ray.cluster_resources()['CPU']))\n",
        "\n",
        "@ray.remote\n",
        "def f():\n",
        "    time.sleep(0.001)\n",
        "    # Return IP address.\n",
        "    return socket.gethostbyname(socket.gethostname())\n",
        "\n",
        "object_ids = [f.remote() for _ in range(10000)]\n",
        "ip_addresses = ray.get(object_ids)\n",
        "\n",
        "with open('/tmp/ray_local_directory_mount/task_stat.txt', 'w') as writer:\n",
        "    print('Tasks executed')\n",
        "    for ip_address, num_tasks in Counter(ip_addresses).items():\n",
        "        rowToWrite = '    {} tasks on {}\\n'.format(num_tasks, ip_address)\n",
        "        print(rowToWrite)\n",
        "        writer.write(rowToWrite)\n",
        "\n",
        "ray.shutdown()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wl4UX4J8ODew",
        "colab_type": "text"
      },
      "source": [
        "**Run following cell only during development in local node. It will show the content written by ray-program and then close the local ray-cluster (a single node cluster with only head-node).**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1fF7kt-lGK8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cat /tmp/ray_local_directory_mount/task_stat.txt\n",
        "!ray stop -v"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyx0ZOc9WF5w",
        "colab_type": "text"
      },
      "source": [
        "**First install google-api-python-client and cryptography library for ray to setup remote cluster in GCP.** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFZ-3GVubTK7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install google-api-python-client==1.7.8\n",
        "!pip install cryptography==2.9.2 #needed internally by ray up"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yauxxMPlZO6t",
        "colab_type": "text"
      },
      "source": [
        "**Following yaml file is the overall configuration file which will define topology of the remote ray-cluster. Note the {{GCP_PROJECT_ID}}, which will be later replaced by your GCP-project-id extracted from your service-account key file (in JSON form). Note that total number of CPUs that you can allocate will be driven by quota-limit in your GCP account. For an example, a free-trial account may not able to allocate more than 8 CPUs. Below I have considered you have enabled billing in your GCP account. In a billable account, GCP allows default 24 CPUs to be allocated in every region. Considering that, the following configuration will create 1 head node of 4 CPUs and 5 additional worker nodes of 4 CPUs.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vwF-_3rcSY1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#refer: https://github.com/ray-project/ray/tree/master/python/ray/autoscaler/gcp\n",
        "\n",
        "%%writefile ray_gcp_cluster.yaml\n",
        "\n",
        "# An unique identifier for the head node and workers of this cluster.\n",
        "cluster_name: \"ray-exp1\"\n",
        "\n",
        "# The minimum number of workers nodes to launch in addition to the head\n",
        "# node. This number should be >= 0.\n",
        "min_workers: 5\n",
        "\n",
        "# The maximum number of workers nodes to launch in addition to the head\n",
        "# node. This takes precedence over min_workers.\n",
        "max_workers: 5\n",
        "\n",
        "# The initial number of worker nodes to launch in addition to the head\n",
        "# node. When the cluster is first brought up (or when it is refreshed with a\n",
        "# subsequent `ray up`) this number of nodes will be started.\n",
        "initial_workers: 5\n",
        "\n",
        "# Whether or not to autoscale aggressively. If this is enabled, if at any point\n",
        "#   we would start more workers, we start at least enough to bring us to\n",
        "#   initial_workers.\n",
        "autoscaling_mode: aggressive\n",
        "\n",
        "# The autoscaler will scale up the cluster to this target fraction of resource\n",
        "# usage. For example, if a cluster of 10 nodes is 100% busy and\n",
        "# target_utilization is 0.8, it would resize the cluster to 13. This fraction\n",
        "# can be decreased to increase the aggressiveness of upscaling.\n",
        "# This value must be less than 1.0 for scaling to happen.\n",
        "#target_utilization_fraction: 0.05\n",
        "\n",
        "# If a node is idle for this many minutes, it will be removed.\n",
        "#idle_timeout_minutes: 1\n",
        "\n",
        "# Cloud-provider specific configuration.\n",
        "provider:\n",
        "    type: gcp\n",
        "    region: us-central1\n",
        "    availability_zone: us-central1-a\n",
        "    project_id: {{GCP_PROJECT_ID}} # Globally unique project id <USER HAD TO USE THEIR OWN GCP PROJECT-ID>\n",
        "\n",
        "# How Ray will authenticate with newly launched nodes.\n",
        "auth:\n",
        "    ssh_user: ray_user\n",
        "# By default Ray creates a new private keypair, but you can also use your own.\n",
        "# If you do so, make sure to also set \"KeyName\" in the head and worker node\n",
        "# configurations below. This requires that you have added the key into the\n",
        "# project wide meta-data.\n",
        "#    ssh_private_key: /path/to/your/key.pem\n",
        "\n",
        "# Provider-specific config for the head node, e.g. instance type. By default\n",
        "# Ray will auto-configure unspecified fields such as subnets and ssh-keys.\n",
        "# For more documentation on available fields, see:\n",
        "# https://cloud.google.com/compute/docs/reference/rest/v1/instances/insert\n",
        "head_node:\n",
        "    machineType: n1-standard-4\n",
        "    disks:\n",
        "      - boot: true\n",
        "        autoDelete: true\n",
        "        type: PERSISTENT\n",
        "        initializeParams:\n",
        "          diskSizeGb: 50\n",
        "          # See https://cloud.google.com/compute/docs/images for more images (Check 'selfLink' in 'Equivalent REST response')\n",
        "          sourceImage: projects/ubuntu-os-cloud/global/images/ubuntu-2004-focal-v20200729\n",
        "\n",
        "    # Additional options can be found in in the compute docs at\n",
        "    # https://cloud.google.com/compute/docs/reference/rest/v1/instances/insert\n",
        "\n",
        "    # If the network interface is specified as below in both head and worker\n",
        "    # nodes, the manual network config is used.  Otherwise an existing subnet is\n",
        "    # used.  To use a shared subnet, ask the subnet owner to grant permission\n",
        "    # for 'compute.subnetworks.use' to the ray autoscaler account...\n",
        "    # networkInterfaces:\n",
        "    #   - kind: compute#networkInterface\n",
        "    #     subnetwork: path/to/subnet\n",
        "    #     aliasIpRanges: []\n",
        "\n",
        "worker_nodes:\n",
        "    machineType: n1-standard-4\n",
        "    disks:\n",
        "      - boot: true\n",
        "        autoDelete: true\n",
        "        type: PERSISTENT\n",
        "        initializeParams:\n",
        "          diskSizeGb: 50\n",
        "          # See https://cloud.google.com/compute/docs/images for more images (Check 'selfLink' in 'Equivalent REST response')\n",
        "          sourceImage: projects/ubuntu-os-cloud/global/images/ubuntu-2004-focal-v20200729\n",
        "    # Run workers on preemtible instance by default.\n",
        "    # Comment this out to use non-premptible ones. Preemptible instances are cheaper, but can be switched off by GCP abruptly.\n",
        "    # Thus never run the head node in preemptible VM instace.\n",
        "    scheduling:\n",
        "      - preemptible: true\n",
        "\n",
        "    # Additional options can be found in in the compute docs at\n",
        "    # https://cloud.google.com/compute/docs/reference/rest/v1/instances/insert\n",
        "\n",
        "# Files or directories to copy to the head and worker nodes. The format is a\n",
        "# dictionary from REMOTE_PATH: LOCAL_PATH, e.g.\n",
        "file_mounts: {\n",
        "   \"/tmp/ray_local_directory_mount\": \"/tmp/ray_local_directory_mount\",\n",
        "   \"~/gcp_service_account.json\": \"/content/gcp_service_account.json\"\n",
        "}\n",
        "\n",
        "# List of commands that will be run before `setup_commands`. If docker is\n",
        "# enabled, these commands will run outside the container and before docker\n",
        "# is setup.\n",
        "initialization_commands:\n",
        "    #disable ipv6 (https://itsfoss.com/disable-ipv6-ubuntu-linux/)\n",
        "    - >-\n",
        "      sudo sysctl -w net.ipv6.conf.all.disable_ipv6=1;\n",
        "      sudo sysctl -w net.ipv6.conf.default.disable_ipv6=1;\n",
        "      sudo sysctl -w net.ipv6.conf.lo.disable_ipv6=1\n",
        "    #firewall is not enabled by default in ubuntu (list out iptable rules to verify that)\n",
        "    - sudo iptables -L\n",
        "    #setup netstat command\n",
        "    - sudo apt -y install net-tools\n",
        "    #link 'python' command to default pytho3\n",
        "    - sudo update-alternatives --install /usr/bin/python python /usr/bin/python3.8 1;\n",
        "    #ensure apt automatically retry installation if internet disconnects (https://askubuntu.com/questions/875213/apt-get-to-retry-downloading)\n",
        "    - sudo touch /etc/apt/apt.conf.d/80-retries\n",
        "    - echo \"APT::Acquire::Retries \\\"10\\\";\" >> /tmp/80-retries\n",
        "    - sudo cp /tmp/80-retries /etc/apt/apt.conf.d/80-retries\n",
        "    - sudo apt update\n",
        "    #install pip3\n",
        "    - sudo apt -y install python3-pip\n",
        "\n",
        "# List of shell commands to run to set up nodes.\n",
        "setup_commands:\n",
        "    # Install ray\n",
        "    - sudo pip3 install ray==0.8.6\n",
        "\n",
        "# Custom commands that will be run on the head node after common setup.\n",
        "head_setup_commands:\n",
        "    - sudo pip3 install google-api-python-client==1.7.8\n",
        "    - sudo pip3 install --upgrade --force-reinstall cryptography==2.9.2\n",
        "    - export GOOGLE_APPLICATION_CREDENTIALS=~/gcp_service_account.json\n",
        "\n",
        "# Custom commands that will be run on worker nodes after common setup.\n",
        "worker_setup_commands: []\n",
        "\n",
        "# Command to start ray on the head node. You don't need to change this.\n",
        "head_start_ray_commands:\n",
        "    - ray stop\n",
        "    - >-\n",
        "      ulimit -n 65536;\n",
        "      ray start --head --port=6379 --object-manager-port=8076 --include-webui=True --webui-host=0.0.0.0 --autoscaling-config=~/ray_bootstrap_config.yaml\n",
        "\n",
        "# Command to start ray on worker nodes. You don't need to change this.\n",
        "worker_start_ray_commands:\n",
        "    - ray stop\n",
        "    - >-\n",
        "      ulimit -n 65536;\n",
        "      ray start --address=$RAY_HEAD_IP:6379 --object-manager-port=8076\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnMxd9ofl4yP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#refer: https://cloud.google.com/iam/docs/service-accounts (Go to 'User-managed service accounts' section)\n",
        "### create a new user-managed service account for ray-experiment from 'IAM & Admin' > 'Service Account') \n",
        "### Give only 'Editor' role for the GCP project (it is good practise not to give 'owner' access to the project)\n",
        "#Refer: https://cloud.google.com/iam/docs/creating-managing-service-account-keys for how to generate the service-account json file\n",
        "#Rename that file as 'gcp_service_account.json' and then upload to google colab using 'upload to session storage' icon\n",
        "import os\n",
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/content/gcp_service_account.json\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mLgdhZlC9jZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "\n",
        "with open(os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"], 'r') as gcp_service_acc_file:\n",
        "    data = json.load(gcp_service_acc_file)\n",
        "    with open('ray_gcp_cluster.yaml', 'r') as ray_cluster_config_file:\n",
        "        config = ray_cluster_config_file.read().replace('{{GCP_PROJECT_ID}}', data['project_id'])\n",
        "    with open('ray_gcp_cluster.yaml', 'w') as ray_cluster_config_file:\n",
        "        ray_cluster_config_file.write(config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6E-nORoprwge",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf /tmp/*\n",
        "!mkdir -p /tmp/ray_local_directory_mount\n",
        "!echo \"Content of /tmp\"\n",
        "!ls -la /tmp\n",
        "!rm -rf /root/.ssh/*\n",
        "!mkdir -p /root/.ssh\n",
        "!echo \"Content of /root\"\n",
        "!ls -la /root\n",
        "!echo \"Content of /root/.ssh\"\n",
        "!ls -la /root/.ssh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QyeGpUmBdg3g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ray up ray_gcp_cluster.yaml"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyoW7yE9Odt-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ray exec ray_gcp_cluster.yaml 'sudo chmod -R ugo+rwx /tmp/ray/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JXiX3XHqQ8T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ray exec ray_gcp_cluster.yaml 'sudo netstat -tulpn | grep LISTEN'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvukxT5pGAEY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ray submit ray_gcp_cluster.yaml ray_test.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2w8qSm4GTNl0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ray rsync-down ray_gcp_cluster.yaml "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUHCnUIrR-cV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cat /tmp/ray_local_directory_mount/task_stat.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIQwdBUTZWdf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ray down ray_gcp_cluster.yaml"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}